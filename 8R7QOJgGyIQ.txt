let's build something with crew AI I'm ['start']: 0.04 ['end']: 2.159
going to set up teams and we're going to ['start']: 2.159 ['end']: 4.08
accomplish tasks together and this is ['start']: 4.08 ['end']: 6.399
going to be a slower paced video because ['start']: 6.399 ['end']: 8.24
I'm just going to build it all with you ['start']: 8.24 ['end']: 10.12
live and we're going to be especially ['start']: 10.12 ['end']: 12.28
focusing on tools because I really want ['start']: 12.28 ['end']: 15.16
to extract the most amount of value from ['start']: 15.16 ['end']: 17.48
allowing agents to use tools and I'm ['start']: 17.48 ['end']: 19.96
going to show you how to access the edge ['start']: 19.96 ['end']: 22.039
version of crew aai which has a bunch of ['start']: 22.039 ['end']: 24.76
native tools installed in addition to ['start']: 24.76 ['end']: 27.279
Lang chain which we can use and then ['start']: 27.279 ['end']: 29.119
custom tools which we can build ['start']: 29.119 ['end']: 30.64
ourselves so I'm going to show you how ['start']: 30.64 ['end']: 32.119
to do that also and we're going to be ['start']: 32.119 ['end']: 34.04
using lightning. a as the IDE in the ['start']: 34.04 ['end']: 37.12
cloud so everything I'm going to do is ['start']: 37.12 ['end']: 39.0
going to be coded in the cloud and then ['start']: 39.0 ['end']: 40.92
I'm going to share the code with you at ['start']: 40.92 ['end']: 42.039
the end of the video and lightning is ['start']: 42.039 ['end']: 43.879
also the sponsor of this video so thank ['start']: 43.879 ['end']: 45.84
you to lightning let's get into it so I ['start']: 45.84 ['end']: 47.96
am literally starting from nothing you ['start']: 47.96 ['end']: 49.719
are going to watch me install it you're ['start']: 49.719 ['end']: 51.199
going to watch me set up all the agents ['start']: 51.199 ['end']: 52.92
line by line so the nice thing about ['start']: 52.92 ['end']: 54.6
lightning AI is it is a cloud ['start']: 54.6 ['end']: 56.64
environment IDE and it's also so much ['start']: 56.64 ['end']: 59.079
more and I'll get to that in a bit but ['start']: 59.079 ['end']: 60.64
it's essentially vs code completely in ['start']: 60.64 ['end']: 62.359
the cloud and you could collaborate with ['start']: 62.359 ['end']: 64.4
other people on the code so right now ['start']: 64.4 ['end']: 66.32
this is from within my browser which is ['start']: 66.32 ['end']: 68.28
really cool and I opened up the terminal ['start']: 68.28 ['end']: 70.64
same thing as vs code so everything ['start']: 70.64 ['end']: 72.4
should feel super familiar to you I ['start']: 72.4 ['end']: 74.24
opened up the terminal right here and ['start']: 74.24 ['end']: 76.68
let's get started I can see we're on ['start']: 76.68 ['end']: 78.96
python ['start']: 78.96 ['end']: 80.159
3.10.1 right there and if I click on it ['start']: 80.159 ['end']: 82.84
I can select another version but we ['start']: 82.84 ['end']: 84.799
don't need another version so what we're ['start']: 84.799 ['end']: 86.36
going to do is PIP install crew aai and ['start']: 86.36 ['end']: 89.96
that's it let's see if it ['start']: 89.96 ['end']: 91.96
goes okay downloading everything that ['start']: 91.96 ['end']: 94.68
should be ['start']: 94.68 ['end']: 102.799
good okay it's done awesome I'm also ['start']: 102.799 ['end']: 106.399
going to have the crew aai documentation ['start']: 106.399 ['end']: 108.719
open just so I can reference it whenever ['start']: 108.719 ['end']: 110.68
I ['start']: 110.68 ['end']: 113.399
need and so now that I have crew AI ['start']: 113.399 ['end']: 116.159
installed that actually should be it to ['start']: 116.159 ['end']: 118.399
get started defining our agents so I'm ['start']: 118.399 ['end']: 121.479
switching over to the documentation I'm ['start']: 121.479 ['end']: 123.159
going to copy the code from the ['start']: 123.159 ['end']: 125.32
documentation I'm going to switch back ['start']: 125.32 ['end']: 127.2
and I'm just going to print it all in ['start']: 127.2 ['end']: 128.759
here and we're going to adjust it as we ['start']: 128.759 ['end']: 130.76
need so let's delete this comment we're ['start']: 130.76 ['end']: 134.28
going to import OS which will allow us ['start']: 134.28 ['end']: 136.319
to handle our API key and we're going to ['start']: 136.319 ['end']: 139.64
be using chat GPT ['start']: 139.64 ['end']: 142.0
initially but we may end up using a ['start']: 142.0 ['end']: 144.2
local model later now the good thing ['start']: 144.2 ['end']: 146.239
about lightning AI is it's not only a ['start']: 146.239 ['end']: 148.599
cloud IDE but you can actually power ['start']: 148.599 ['end']: 150.879
models you can spin up gpus and power ['start']: 150.879 ['end']: 153.319
open- source models and directly connect ['start']: 153.319 ['end']: 155.519
them to whatever application You're ['start']: 155.519 ['end']: 157.319
Building lightning is really made for AI ['start']: 157.319 ['end']: 161.159
applications so I switched over to ['start']: 161.159 ['end']: 163.44
create new keys and open AI let's hit ['start']: 163.44 ['end']: 165.879
create new key and I'm going to type ['start']: 165.879 ['end']: 168.239
crew yt2 because I already started one ['start']: 168.239 ['end']: 171.56
and I'm starting another one create ['start']: 171.56 ['end']: 173.28
secret key copy I'm going to revoke this ['start']: 173.28 ['end']: 176.08
key before publishing the video of ['start']: 176.08 ['end']: 178.239
course and right here on line ['start']: 178.239 ['end']: 181.44
four I'm going to double click and enter ['start']: 181.44 ['end']: 183.72
my API ['start']: 183.72 ['end']: 185.72
key and I'm realizing that by habit I'm ['start']: 185.72 ['end']: 189.12
hitting save often and I probably don't ['start']: 189.12 ['end']: 191.84
need to do that with lightning because ['start']: 191.84 ['end']: 193.2
it saves automatically as I'm going so ['start']: 193.2 ['end']: 195.879
I'm going to rightclick on main.py right ['start']: 195.879 ['end']: 198.0
over here and I'm going to go down to ['start']: 198.0 ['end']: 199.72
rename and I'm going to call it crew. ['start']: 199.72 ['end']: 202.599
py okay and I realize I already made a ['start']: 202.599 ['end']: 205.799
mistake because if we just do pip ['start']: 205.799 ['end']: 208.68
install crew AI it's going to install ['start']: 208.68 ['end']: 211.12
the latest stable release but what we ['start']: 211.12 ['end']: 213.68
want to do is actually hit equals ['start']: 213.68 ['end']: 217.599
equals and then insert ['start']: 217.599 ['end']: 220.56
0.14.0 RC so what we're going to do ['start']: 220.56 ['end']: 223.4
first is PIP uninstall crew ['start']: 223.4 ['end']: 228.439
aai and so now you can see I make ['start']: 228.439 ['end']: 230.599
mistakes all the time and then we're ['start']: 230.599 ['end']: 232.84
going to do pip install crew AI equals ['start']: 232.84 ['end']: 235.599
equals and then ['start']: 235.599 ['end']: 237.92
0.14.0 RC ['start']: 237.92 ['end']: 240.239
and then we hit ['start']: 240.239 ['end']: 258.56
enter okay so it's installing the newest ['start']: 258.56 ['end']: 261.68
version and I got a list of the tools ['start']: 261.68 ['end']: 264.16
and they're not documented yet but I'm ['start']: 264.16 ['end']: 266.0
going to show you what they are and I'll ['start']: 266.0 ['end']: 267.4
add them as a comment in this file right ['start']: 267.4 ['end']: 269.36
here once this is done okay it's ['start']: 269.36 ['end']: 275.12
done okay so before we continue I'm just ['start']: 275.12 ['end']: 278.96
going to add a comment right here these ['start']: 278.96 ['end']: 280.56
are the tools that we will soon have ['start']: 280.56 ['end']: 282.479
access to in the main version but in the ['start']: 282.479 ['end']: 285.4
release client we can access them right ['start']: 285.4 ['end']: 288.759
now so comment those out so we have code ['start']: 288.759 ['end']: 291.68
doc Search tool CSV Search tool ['start']: 291.68 ['end']: 294.68
directory Search tool we have a txt ['start']: 294.68 ['end']: 296.639
Search tool Json all the way down we ['start']: 296.639 ['end']: 298.44
have website search Tool YouTube video ['start']: 298.44 ['end']: 301.28
search tool so we have a lot of ['start']: 301.28 ['end']: 303.12
different tools that we're going to be ['start']: 303.12 ['end']: 304.16
using now I think the first crew I want ['start']: 304.16 ['end']: 306.0
to create is something that I need ['start']: 306.0 ['end']: 307.6
personally and a lot of you ask hey AI ['start']: 307.6 ['end']: 309.88
agents are great but what is the real ['start']: 309.88 ['end']: 312.28
world use case for them and so that's ['start']: 312.28 ['end']: 314.199
what I'm going to show you today I ['start']: 314.199 ['end']: 315.84
collect links for AI news all throughout ['start']: 315.84 ['end']: 318.52
the week and I'm starting to put out a ['start']: 318.52 ['end']: 320.759
newsletter more frequently than I have ['start']: 320.759 ['end']: 322.84
in the past so first be sure to sign up ['start']: 322.84 ['end']: 324.919
for my newsletter the link is in the ['start']: 324.919 ['end']: 326.68
description below but what I want to do ['start']: 326.68 ['end']: 329.72
is create a crew that I can drop a bunch ['start']: 329.72 ['end']: 331.8
of links into they go check out what ['start']: 331.8 ['end']: 333.759
each of the articles are about and then ['start']: 333.759 ['end']: 335.4
just write a short summary of each one ['start']: 335.4 ['end']: 337.72
and that'll just save me a bunch of time ['start']: 337.72 ['end']: 339.24
when I'm creating the newsletter myself ['start']: 339.24 ['end']: 341.039
so here's an example of how to use a ['start']: 341.039 ['end']: 342.44
tool from Lang chain so from Lang chain ['start']: 342.44 ['end']: 344.6
community. tools import duck. go search ['start']: 344.6 ['end']: 347.08
run and we just set it as a Search tool ['start']: 347.08 ['end']: 350.319
but we're not going to need that so ['start']: 350.319 ['end']: 351.52
let's go ahead and delete that there and ['start']: 351.52 ['end']: 353.639
I'm going to give us a little bit more ['start']: 353.639 ['end']: 354.96
room in the code editor so the first ['start']: 354.96 ['end']: 357.96
agent being created is the researcher ['start']: 357.96 ['end']: 360.08
agent and I'm going to be changing that ['start']: 360.08 ['end']: 361.96
so we're going to call it the scraper ['start']: 361.96 ['end']: 364.4
agent and the role is ['start']: 364.4 ['end']: 369.759
to actually I'm going to change that to ['start']: 369.759 ['end']: 371.96
the summarizer ['start']: 371.96 ['end']: 374.88
agent and the role will ['start']: 374.88 ['end']: 380.319
be summarizer of ['start']: 380.319 ['end']: 384.599
websites goal let's set that to Let's ['start']: 384.599 ['end']: 389.56
see what should we set that to that'll ['start']: 389.56 ['end']: 392.319
be go to a given ['start']: 392.319 ['end']: 395.599
website scrape the ['start']: 395.599 ['end']: 398.72
content and provide a summary of ['start']: 398.72 ['end']: 404.8
the article on the ['start']: 404.8 ['end']: 408.639
website okay ['start']: 408.639 ['end']: 411.84
backstory let's give it a little bit of ['start']: 411.84 ['end']: 413.8
backstory you work at a leading Tech ['start']: 413.8 ['end']: 416.639
Think Tank that's fine your expertise ['start']: 416.639 ['end']: 418.759
lies in identifying emerging Trends ['start']: 418.759 ['end']: 421.199
that's fine you have a knack for ['start']: 421.199 ['end']: 422.96
dissecting complex data and presenting ['start']: 422.96 ['end']: 424.8
actionable insights so I don't need that ['start']: 424.8 ['end']: 427.759
and we're going to say you have a knack ['start']: 427.759 ['end']: 431.599
for taking complex ['start']: 431.599 ['end']: 437.199
topics AI ['start']: 437.199 ['end']: 439.199
topics and explaining them clearly and ['start']: 439.199 ['end']: 448.039
succinctly with ['start']: 448.039 ['end']: 450.039
a bit of ['start']: 450.039 ['end']: 454.4
wit okay we're going to keep verbos true ['start']: 454.4 ['end']: 457.8
because we want to see all the output ['start']: 457.8 ['end']: 459.56
and I don't want this summarizer agent ['start']: 459.56 ['end']: 462.52
to delegate anything and that's ['start']: 462.52 ['end']: 464.96
something really nice with crew AI is ['start']: 464.96 ['end']: 466.4
you can allow for delegation really ['start']: 466.4 ['end']: 468.08
easily now for the tool it says Search ['start']: 468.08 ['end']: 470.72
tool so we do need to change that I'm ['start']: 470.72 ['end']: 473.4
going to delete all these ['start']: 473.4 ['end']: 476.56
comments and by default it will use GPT ['start']: 476.56 ['end']: 481.68
4 so for the Search tool rather than ['start']: 481.68 ['end']: 484.36
that we're actually going to use the ['start']: 484.36 ['end']: 486.919
website Search tool and I think the ['start']: 486.919 ['end']: 489.8
website Search tool goes and scrapes a ['start']: 489.8 ['end']: 491.879
website but we'll see again I'm doing ['start']: 491.879 ['end']: 494.28
this for the first time we'll do it ['start']: 494.28 ['end']: 497.96
together all right next we have the ['start']: 497.96 ['end']: 500.28
writer agent and that is good and the ['start']: 500.28 ['end']: 503.36
role is a tech ['start']: 503.36 ['end']: 507.319
content summarizer and ['start']: 507.319 ['end']: 511.68
writer goal craft compelling ['start']: 511.68 ['end']: 516.36
content ['start']: 516.36 ['end']: 517.959
on AI ['start']: 517.959 ['end']: 520.479
advancements and we're going to actually ['start']: 520.479 ['end']: 522.159
say craft compelling short form content ['start']: 522.159 ['end']: 525.279
on AI ['start']: 525.279 ['end']: 527.36
advancements backstory you are a ['start']: 527.36 ['end']: 529.6
renowned content ['start']: 529.6 ['end']: 532.32
creator known for your insightful and ['start']: 532.32 ['end']: 534.8
engaging articles you transform complex ['start']: 534.8 ['end']: 537.24
Concepts into compelling narratives that ['start']: 537.24 ['end']: 539.44
sounds good verbose true allow ['start']: 539.44 ['end']: 541.68
delegation true we do not want this ['start']: 541.68 ['end']: 544.76
agent to ['start']: 544.76 ['end']: 546.079
delegate actually maybe we do because ['start']: 546.079 ['end']: 549.36
the writer is going to delegate the ['start']: 549.36 ['end']: 552.16
scraping to the summarizer I think ['start']: 552.16 ['end']: 554.279
that's how it could work so let's leave ['start']: 554.279 ['end']: 556.68
delegation ['start']: 556.68 ['end']: 560.32
on now we have two tasks let's see what ['start']: 560.32 ['end']: 563.64
they ['start']: 563.64 ['end']: 564.56
are task one conduct a comprehensive ['start']: 564.56 ['end']: 568.279
analysis of the latest advancements in ['start']: 568.279 ['end']: 570.399
AI in 2024 okay so we're going to change ['start']: 570.399 ['end']: 574.6
this we're going to say for task one ['start']: 574.6 ['end']: 578.68
take a list of ['start']: 578.68 ['end']: 581.959
websites that contain AI ['start']: 581.959 ['end']: 586.16
content read SL scrape the ['start']: 586.16 ['end']: 590.32
content and then provide a short ['start']: 590.32 ['end']: 595.16
summary a short ['start']: 595.16 ['end']: 597.399
and interesting SL compelling ['start']: 597.399 ['end']: 603.92
summary of the content found on the ['start']: 603.92 ['end']: 609.88
website okay and we're going to give ['start']: 609.88 ['end']: 613.24
this to the ['start']: 613.24 ['end']: 616.88
writer actually now that I'm thinking ['start']: 616.88 ['end']: 619.12
about it the first task needs to be ['start']: 619.12 ['end']: 621.8
going and getting the content so let's ['start']: 621.8 ['end']: 624.24
do that first so I'm going to say the ['start']: 624.24 ['end']: 628.04
summarizer ['start']: 628.04 ['end']: 630.72
is actually going to be a scraper agent ['start']: 630.72 ['end']: 633.2
so that's their only job is to go get ['start']: 633.2 ['end']: 635.519
the content so let's change just a ['start']: 635.519 ['end']: 637.399
little bit scrape the content and ['start']: 637.399 ['end']: 641.44
provide the full content to ['start']: 641.44 ['end']: 645.56
the writer ['start']: 645.56 ['end']: 650.079
agent so it can then be ['start']: 650.079 ['end']: 656.56
summarized and r rather than this ['start']: 656.56 ['end']: 660.12
backstory I'll leave leading think tank ['start']: 660.12 ['end']: 663.12
but we're going to change this to ['start']: 663.12 ['end']: 665.639
be your expertise ['start']: 665.639 ['end']: 669.8
is taking URLs ['start']: 669.8 ['end']: 673.6
and getting just the text based ['start']: 673.6 ['end']: 678.24
content of ['start']: 678.24 ['end']: 682.0
them ['start']: 682.0 ['end']: 683.519
okay then for the ['start']: 683.519 ['end']: 686.639
writer craft compelling short form ['start']: 686.639 ['end']: 689.04
content on AI ['start']: 689.04 ['end']: 691.279
advancements based ['start']: 691.279 ['end']: 693.48
on long ['start']: 693.48 ['end']: 696.32
form text passed to ['start']: 696.32 ['end']: 700.24
you okay so task ['start']: 700.24 ['end']: 704.0
one take the list of websites that ['start']: 704.0 ['end']: 707.04
contain AI content read scrape the ['start']: 707.04 ['end']: 709.24
content and then provide so we're going ['start']: 709.24 ['end']: 711.44
to change ['start']: 711.44 ['end']: 714.079
this and then so read scrape the content ['start']: 714.079 ['end']: 717.88
and then pass it to the writer ['start']: 717.88 ['end']: 722.279
agent so this is going to be the ['start']: 722.279 ['end']: 725.0
scraper and then we have the ['start']: 725.0 ['end']: 727.6
writer using the text ['start']: 727.6 ['end']: 731.8
provided by the scraper agent ['start']: 731.8 ['end']: 736.76
develop an engaging blog post so I'm ['start']: 736.76 ['end']: 739.56
going to change this ['start']: 739.56 ['end']: 741.279
now develop a short and compelling slash ['start']: 741.279 ['end']: 747.88
interesting short form summary of ['start']: 747.88 ['end']: 754.199
the text provided to ['start']: 754.199 ['end']: 759.12
you about AI let's see what happens ['start']: 759.12 ['end']: 762.24
we're probably going to have to iterate ['start']: 762.24 ['end']: 763.44
on this a few times so we have task one ['start']: 763.44 ['end']: 766.399
task two we create a crew right here ['start']: 766.399 ['end']: 769.079
we're going to have two agents in the ['start']: 769.079 ['end']: 770.56
crew we're going to have the scraper ['start']: 770.56 ['end']: 771.8
agent and the writer agent we have task ['start']: 771.8 ['end']: 774.0
one task two and verbose equals two you ['start']: 774.0 ['end']: 776.44
can set it to either one or two to ['start']: 776.44 ['end']: 779.04
different logging levels and we're going ['start']: 779.04 ['end']: 781.199
to leave it as two so then we get the ['start']: 781.199 ['end']: 784.199
result ['start']: 784.199 ['end']: 786.12
and we go ahead and print the ['start']: 786.12 ['end']: 791.32
result ['start']: 791.32 ['end']: 793.48
okay so one thing we're going to have to ['start']: 793.48 ['end']: 796.6
do is figure out a way to pass in the ['start']: 796.6 ['end']: 799.68
list of ['start']: 799.68 ['end']: 800.72
Articles so let's see if we could do ['start']: 800.72 ['end']: 802.959
that right here ask the user for a list ['start']: 802.959 ['end']: 806.44
of urls then go ['start']: 806.44 ['end']: 811.16
to each given website scrape the content ['start']: 811.16 ['end']: 814.639
and provide ['start']: 814.639 ['end']: 816.48
the full content to the writer agent so ['start']: 816.48 ['end']: 819.279
it can be summarized so let's see if ['start']: 819.279 ['end']: 821.24
this works we might need to actually ['start']: 821.24 ['end']: 823.079
pass the URLs directly in ['start']: 823.079 ['end']: 826.839
here well let's see all right let's play ['start']: 826.839 ['end']: 829.88
it and see what happens so I'm going to ['start']: 829.88 ['end']: 832.279
clear everything in there let's hit play ['start']: 832.279 ['end']: 835.519
and let's watch it ['start']: 835.519 ['end']: 837.759
work ['start']: 837.759 ['end']: 842.279
okay name error website tool is not ['start']: 842.279 ['end']: 844.56
defined right okay so we still need to ['start']: 844.56 ['end']: 848.12
actually Define it up here to be able to ['start']: 848.12 ['end']: 849.959
use ['start']: 849.959 ['end']: 852.639
it so I think this is going to be how we ['start']: 852.639 ['end']: 855.6
do it so from crew aai tools and we ['start']: 855.6 ['end']: 858.16
don't actually have that so let's add ['start']: 858.16 ['end']: 860.079
that ['start']: 860.079 ['end']: 861.8
here now this is not documented at all ['start']: 861.8 ['end']: 864.44
so it's a little bit difficult to figure ['start']: 864.44 ['end']: 866.279
out but we'll try crew a crew a AI tools ['start']: 866.279 ['end']: 870.519
let's see if we just hover over it do we ['start']: 870.519 ['end']: 872.72
get any ['start']: 872.72 ['end']: 875.519
information okay I don't think this is ['start']: 875.519 ['end']: 878.079
right crew AI tools ['start']: 878.079 ['end']: 880.759
maybe okay let's try ['start']: 880.759 ['end']: 883.16
that ['start']: 883.16 ['end']: 884.839
then from crew aai ['start']: 884.839 ['end']: 887.959
tools we're going to ['start']: 887.959 ['end']: 890.759
import the website Search ['start']: 890.759 ['end']: 896.24
tool just like that and we're going to ['start']: 896.24 ['end']: 898.44
set set it to ['start']: 898.44 ['end']: 902.199
website let's see what do we call it ['start']: 902.199 ['end']: 904.8
down there website Search ['start']: 904.8 ['end']: 906.72
tool let's look at another example of ['start']: 906.72 ['end']: 909.24
how it's done real ['start']: 909.24 ['end']: 911.399
quick so right ['start']: 911.399 ['end']: 914.399
here Search tool okay so we can name it ['start']: 914.399 ['end']: 918.279
anything we ['start']: 918.279 ['end']: 919.32
want website ['start']: 919.32 ['end']: 921.92
Search tool ['start']: 921.92 ['end']: 924.839
equals okay so let's do this a little ['start']: 924.839 ['end']: 927.6
different what we need to do is put this ['start']: 927.6 ['end']: 930.68
on a separate line so we're importing ['start']: 930.68 ['end']: 932.48
the library first then we set it like ['start']: 932.48 ['end']: 938.399
this just like that I'm going to copy ['start']: 938.399 ['end']: 941.12
this make sure that it matches the tool ['start']: 941.12 ['end']: 943.399
down here so it's actually ['start']: 943.399 ['end']: 945.44
using uppercase so let's just change ['start']: 945.44 ['end']: 949.16
that just like that okay we're going to ['start']: 949.16 ['end']: 952.519
save there seems to be an error so I ['start']: 952.519 ['end']: 955.759
think we can maybe delete the ['start']: 955.759 ['end']: 957.959
parentheses off of that and that might ['start']: 957.959 ['end']: 960.16
work let's see ['start']: 960.16 ['end']: 966.0
play okay import error cannot import ['start']: 966.0 ['end']: 968.56
name crew AI tools from crew ['start']: 968.56 ['end']: 971.36
AI maybe we don't need to have crew AI ['start']: 971.36 ['end']: 974.319
tools up there feels like we do but ['start']: 974.319 ['end']: 977.36
maybe not let's ['start']: 977.36 ['end']: 979.959
see okay all right great that worked so ['start']: 979.959 ['end']: 983.0
this is how it's done so crew aai tools ['start']: 983.0 ['end']: 985.279
is already going to be built in and we ['start']: 985.279 ['end']: 987.44
just say from crew AI tools import and ['start']: 987.44 ['end']: 989.8
then the tool that we ['start']: 989.8 ['end']: 991.279
want now let's see what we ['start']: 991.279 ['end']: 997.44
got ['start']: 997.44 ['end']: 999.24
okay starting ['start']: 999.24 ['end']: 1001.56
task entering new crew ['start']: 1001.56 ['end']: 1005.56
executor sure could you please provide ['start']: 1005.56 ['end']: 1007.92
me with a list of URLs you want to ['start']: 1007.92 ['end']: 1009.44
scrape error I didn't use the right ['start']: 1009.44 ['end']: 1012.079
format I must either use a tool use one ['start']: 1012.079 ['end']: 1014.959
at a time or give my best final ['start']: 1014.959 ['end']: 1017.48
answer ['start']: 1017.48 ['end']: 1019.04
okay so we did not do this right I'm ['start']: 1019.04 ['end']: 1020.839
going to stop ['start']: 1020.839 ['end']: 1022.279
it and it's nice because all the same ['start']: 1022.279 ['end']: 1024.4
keyboard Keys work with lightning AI uh ['start']: 1024.4 ['end']: 1026.799
that you're familiar with with vs code ['start']: 1026.799 ['end']: 1029.439
so I'm going to look at some of the ['start']: 1029.439 ['end']: 1031.0
examples so let's look at the stock ['start']: 1031.0 ['end']: 1032.48
analysis right ['start']: 1032.48 ['end']: 1038.72
there so we have tools just like that ['start']: 1038.72 ['end']: 1042.199
that's good okay that's how we have it ['start']: 1042.199 ['end']: 1044.52
backstory best financial ['start']: 1044.52 ['end']: 1047.4
analysis ['start']: 1047.4 ['end']: 1051.64
okay now let's look at the actual ['start']: 1051.64 ['end']: 1058.16
code so here's the code for the ['start']: 1058.16 ['end']: 1061.88
agents okay so all the agents are ['start']: 1061.88 ['end']: 1064.0
defined in one file that's cool we could ['start']: 1064.0 ['end']: 1065.96
do that and then we have the actual ['start']: 1065.96 ['end']: 1072.52
task so the financial anal financial ['start']: 1072.52 ['end']: 1076.76
analysis takes self and ['start']: 1076.76 ['end']: 1083.36
agent but where does it actually ['start']: 1083.36 ['end']: 1088.48
Define the stock that we want to analyze ['start']: 1088.48 ['end']: 1092.6
let's ['start']: 1092.6 ['end']: 1095.36
look okay let's look at main.py maybe ['start']: 1095.36 ['end']: 1097.88
we're passing it in ['start']: 1097.88 ['end']: 1100.84
there okay I see what's being done here ['start']: 1100.84 ['end']: 1103.72
so in the python script itself the first ['start']: 1103.72 ['end']: 1107.4
thing we're doing manually is asking for ['start']: 1107.4 ['end']: 1110.4
the input we save it as ['start']: 1110.4 ['end']: 1113.12
company and then we pass it into ['start']: 1113.12 ['end']: 1115.76
Financial crew and then the crew does ['start']: 1115.76 ['end']: 1118.159
the rest so that's what we're going to ['start']: 1118.159 ['end']: 1119.559
need to set up so I'm not sure how to do ['start']: 1119.559 ['end']: 1121.36
that but we'll figure it out ['start']: 1121.36 ['end']: 1123.6
together okay so I'm going to first copy ['start']: 1123.6 ['end']: 1125.799
this ['start']: 1125.799 ['end']: 1127.159
code let's just take that and we know ['start']: 1127.159 ['end']: 1129.84
we're going to need something like this ['start']: 1129.84 ['end']: 1131.559
so we'll put it in ['start']: 1131.559 ['end']: 1134.24
here and it's probably going to replace ['start']: 1134.24 ['end']: 1137.559
something around here so I'm going to ['start']: 1137.559 ['end']: 1139.84
leave everything in one file for now ['start']: 1139.84 ['end']: 1142.0
just to simplify ['start']: 1142.0 ['end']: 1143.76
things let's paste that code in so ['start']: 1143.76 ['end']: 1147.88
instead of this so this is the main part ['start']: 1147.88 ['end']: 1150.64
of the Python code we're going to be ['start']: 1150.64 ['end']: 1152.039
running so I'm going to actually change ['start']: 1152.039 ['end']: 1153.88
this back to ['start']: 1153.88 ['end']: 1158.24
main.py and then we're going to say ['start']: 1158.24 ['end']: 1160.679
welcome ['start']: 1160.679 ['end']: 1163.72
to newsletter ['start']: 1163.72 ['end']: 1167.24
writer ['start']: 1167.24 ['end']: 1170.679
okay uh and then we're going to say ['start']: 1170.679 ['end']: 1175.36
websites what is the company you want to ['start']: 1175.36 ['end']: 1177.4
analyze we'll see what is the URL you ['start']: 1177.4 ['end']: 1180.72
want to ['start']: 1180.72 ['end']: 1183.919
summarize and then Financial crew we're ['start']: 1183.919 ['end']: 1186.24
going to call it newsletter ['start']: 1186.24 ['end']: 1192.919
crew newsletter ['start']: 1192.919 ['end']: 1195.52
crew okay so let's call this ['start']: 1195.52 ['end']: 1200.64
this ['start']: 1200.64 ['end']: 1203.72
newsletter oops newsletter ['start']: 1203.72 ['end']: 1207.32
crew ['start']: 1207.32 ['end']: 1211.32
okay that might work let's just make ['start']: 1211.32 ['end']: 1213.72
sure all the capitalization is ['start']: 1213.72 ['end']: 1218.6
correct and then we want to do ['start']: 1218.6 ['end']: 1221.52
newsletter crew. run here is the ['start']: 1221.52 ['end']: 1226.799
result okay ['start']: 1226.799 ['end']: 1230.88
so I'm wondering why the newsletter crew ['start']: 1230.88 ['end']: 1233.12
up here has run and this one has kickoff ['start']: 1233.12 ['end']: 1235.52
so let's double ['start']: 1235.52 ['end']: 1238.72
check okay so let's look ['start']: 1238.72 ['end']: 1242.96
at the task here we go so stock analysis ['start']: 1242.96 ['end']: 1249.44
task and I really like how he keeps all ['start']: 1249.44 ['end']: 1251.84
of his code really modular so I might ['start']: 1251.84 ['end']: 1253.88
copy that but for now let's try to do it ['start']: 1253.88 ['end']: 1255.52
without ['start']: 1255.52 ['end']: 1257.12
that ['start']: 1257.12 ['end']: 1258.919
okay let's look at the ['start']: 1258.919 ['end']: 1261.799
agents okay I'm going to go back to ['start']: 1261.799 ['end']: 1263.64
main.py and I'm just trying to figure ['start']: 1263.64 ['end']: 1265.6
out how he set all this up so I can ['start']: 1265.6 ['end']: 1267.679
essentially mimic the same thing that he ['start']: 1267.679 ['end']: 1272.679
did okay so he does have crew right here ['start']: 1272.679 ['end']: 1276.0
and this whole thing okay I see I see so ['start']: 1276.0 ['end']: 1278.799
the whole thing is wrapped with this ['start']: 1278.799 ['end']: 1280.48
class so I think that's what we're going ['start']: 1280.48 ['end']: 1281.919
to have to do so I'm going to copy all ['start']: 1281.919 ['end']: 1284.0
of ['start']: 1284.0 ['end']: 1287.039
this ['start']: 1287.039 ['end']: 1289.039
and actually I'm just going to copy the ['start']: 1289.039 ['end']: 1290.279
top part I think that's all all we're ['start']: 1290.279 ['end']: 1292.6
going to ['start']: 1292.6 ['end']: 1294.32
need then we in instantiate our agents ['start']: 1294.32 ['end']: 1297.84
right there and task but we're going to ['start']: 1297.84 ['end']: 1299.799
Define them in the file itself so I'm ['start']: 1299.799 ['end']: 1301.279
going to hit ['start']: 1301.279 ['end']: 1305.32
copy and then at the very ['start']: 1305.32 ['end']: 1308.88
top let's add in the ['start']: 1308.88 ['end']: 1312.6
class we're not going to Define our ['start']: 1312.6 ['end']: 1314.84
agents and task like ['start']: 1314.84 ['end']: 1316.72
this we do need to indent this so they ['start']: 1316.72 ['end']: 1319.72
fall under run because that is how he ['start']: 1319.72 ['end']: 1321.96
did ['start']: 1321.96 ['end']: 1327.32
it and let me just make sure about the ['start']: 1327.32 ['end']: 1332.36
yeah this is also ['start']: 1332.36 ['end']: 1339.2
indented ['start']: 1339.2 ['end']: 1342.08
okay so let's go back to ['start']: 1342.08 ['end']: 1346.08
lightning and we do need to indent ['start']: 1346.08 ['end']: 1349.12
everything under this new class that we ['start']: 1349.12 ['end']: 1351.039
just ['start']: 1351.039 ['end']: 1357.919
created go ahead and indent ['start']: 1357.919 ['end']: 1360.919
it and ['start']: 1360.919 ['end']: 1364.24
now we have scraper okay we need to ['start']: 1364.24 ['end']: 1367.44
indent one more ['start']: 1367.44 ['end']: 1369.24
time everything should be within run I ['start']: 1369.24 ['end']: 1372.64
believe let me just double ['start']: 1372.64 ['end']: 1375.559
check def run ['start']: 1375.559 ['end']: 1379.2
okay right so this is actually outside ['start']: 1379.2 ['end']: 1380.96
of the class when we actually have to ['start']: 1380.96 ['end']: 1382.159
run it so let's make sure to do ['start']: 1382.159 ['end']: 1385.799
that so this is a top level piece of ['start']: 1385.799 ['end']: 1391.24
code and that should be good now up here ['start']: 1391.24 ['end']: 1396.44
we're going to change this to ['start']: 1396.44 ['end']: 1401.279
be newsletter ['start']: 1401.279 ['end']: 1404.159
crew and we don't want company but we ['start']: 1404.159 ['end']: 1406.88
want URL ['start']: 1406.88 ['end']: 1418.679
URLs I'm going to change this to the ['start']: 1418.679 ['end']: 1424.52
URLs and somehow we have to pass those ['start']: 1424.52 ['end']: 1427.44
URLs into the actual agents so let's see ['start']: 1427.44 ['end']: 1431.48
how we're going to do ['start']: 1431.48 ['end']: 1433.039
that okay self andit company right here ['start']: 1433.039 ['end']: 1436.679
so let's keep this as as ['start']: 1436.679 ['end']: 1439.52
URLs need ['start']: 1439.52 ['end']: 1442.919
that got it okay so now at the bottom ['start']: 1442.919 ['end']: 1447.32
right here newsletter crew not company ['start']: 1447.32 ['end']: 1449.36
but ['start']: 1449.36 ['end']: 1450.76
URLs okay so now it gets passed in URLs ['start']: 1450.76 ['end']: 1453.96
and let's make sure that the agents ['start']: 1453.96 ['end']: 1456.88
within the screw have access to those ['start']: 1456.88 ['end']: 1460.919
URLs so let's see how they defined it in ['start']: 1460.919 ['end']: 1463.559
here so we're going to switch over to ['start']: 1463.559 ['end']: 1466.0
stock analysis agents the definition ['start']: 1466.0 ['end']: 1468.08
because this is where this is where they ['start']: 1468.08 ['end']: 1470.24
would be passing in the URLs I believe ['start']: 1470.24 ['end']: 1472.159
or the company in this ['start']: 1472.159 ['end']: 1474.159
case okay but it doesn't seem to be ['start']: 1474.159 ['end']: 1476.24
doing it here let's see maybe it's ['start']: 1476.24 ['end']: 1478.039
passing it into the task yeah company ['start']: 1478.039 ['end']: 1481.0
okay and then that's how we do it okay ['start']: 1481.0 ['end']: 1483.44
so we're going to have to insert it just ['start']: 1483.44 ['end']: 1485.279
like that selected company by the ['start']: 1485.279 ['end']: 1488.2
customer so let's do ['start']: 1488.2 ['end']: 1490.96
that so if we add two new lines right ['start']: 1490.96 ['end']: 1494.679
here and then we say something like here ['start']: 1494.679 ['end']: 1497.08
are the URLs from the user that you need ['start']: 1497.08 ['end']: 1500.64
to scrape and then we say uh open curly ['start']: 1500.64 ['end']: 1505.159
braces and then URLs hopefully this ['start']: 1505.159 ['end']: 1508.08
works let's see okay so this should be ['start']: 1508.08 ['end']: 1511.76
done and I'm going to go ahead and clear ['start']: 1511.76 ['end']: 1514.679
the output in there and then let's push ['start']: 1514.679 ['end']: 1522.08
play okay Dent is not defined right cuz ['start']: 1522.08 ['end']: 1527.36
I didn't to find it ['start']: 1527.36 ['end']: 1529.24
anywhere Dent let's see where we ['start']: 1529.24 ['end']: 1531.6
actually have ['start']: 1531.6 ['end']: 1534.44
that ['start']: 1534.44 ['end']: 1538.72
dent ['start']: 1538.72 ['end']: 1540.399
okay let's see Dent must be right there ['start']: 1540.399 ['end']: 1545.44
perfect okay so we're going to find that ['start']: 1545.44 ['end']: 1548.48
from text drop let's go ahead and import ['start']: 1548.48 ['end']: 1551.44
that into our ['start']: 1551.44 ['end']: 1555.159
code okay then let's run it again ['start']: 1555.159 ['end']: 1563.24
all right there we go so it asked me for ['start']: 1563.24 ['end']: 1565.96
a ['start']: 1565.96 ['end']: 1566.88
URL that is perfect what is the URL you ['start']: 1566.88 ['end']: 1570.039
want to summarize now I want to be able ['start']: 1570.039 ['end']: 1571.72
to pass multiple in but for this first ['start']: 1571.72 ['end']: 1573.64
iteration I'm just going to give it one ['start']: 1573.64 ['end']: 1576.12
so I found this article AI startup ['start']: 1576.12 ['end']: 1578.0
Runway is raising a venture capital fund ['start']: 1578.0 ['end']: 1581.24
and this was from a couple weeks ago so ['start']: 1581.24 ['end']: 1583.64
that is what I'm going to start ['start']: 1583.64 ['end']: 1585.24
with let's switch back to the code URL I ['start']: 1585.24 ['end']: 1588.24
want to summarize paste it in hit enter ['start']: 1588.24 ['end']: 1591.72
okay name crew is not defined did you ['start']: 1591.72 ['end']: 1593.76
mean crew maybe let's find out so ['start']: 1593.76 ['end']: 1596.159
lowercase crew as compared to uppercase ['start']: 1596.159 ['end']: 1603.52
crew crew is not defined let's find that ['start']: 1603.52 ['end']: 1606.64
lowercase ['start']: 1606.64 ['end']: 1608.679
crew here we go right there so maybe I ['start']: 1608.679 ['end']: 1613.039
did mean uppercase but that oh right we ['start']: 1613.039 ['end']: 1617.799
don't ['start']: 1617.799 ['end']: 1619.799
actually need to do that we need to ['start']: 1619.799 ['end']: 1621.88
actually ['start']: 1621.88 ['end']: 1623.679
say newsletter ['start']: 1623.679 ['end']: 1626.64
crew and I think that is what is wrong ['start']: 1626.64 ['end']: 1630.72
so let's try it ['start']: 1630.72 ['end']: 1633.64
again push play it's going to ask me for ['start']: 1633.64 ['end']: 1636.919
that URL ['start']: 1636.919 ['end']: 1638.64
again let's get it ['start']: 1638.64 ['end']: 1640.64
again paste it hit enter okay type ['start']: 1640.64 ['end']: 1645.08
attribute or attribute error type ['start']: 1645.08 ['end']: 1647.08
objects newsletter crew has no attribute ['start']: 1647.08 ['end']: 1650.159
kickoff interesting let's find out ['start']: 1650.159 ['end']: 1652.72
what's we're doing wrong ['start']: 1652.72 ['end']: 1654.919
here ah we don't need to do that here ['start']: 1654.919 ['end']: 1658.399
okay so the newsletter crew is actually ['start']: 1658.399 ['end']: 1660.24
run from right here so I have duplicate ['start']: 1660.24 ['end']: 1662.72
code so let's get rid of that but I'm ['start']: 1662.72 ['end']: 1666.039
not quite ['start']: 1666.039 ['end']: 1668.32
sure if this is going to work still ['start']: 1668.32 ['end']: 1670.84
because I feel like it should have hit ['start']: 1670.84 ['end']: 1672.399
this first but maybe it only does that ['start']: 1672.399 ['end']: 1674.32
after loading all the other code and um ['start']: 1674.32 ['end']: 1677.799
exposing my lack of experience with uh ['start']: 1677.799 ['end']: 1681.399
python here so glad I'm doing this you ['start']: 1681.399 ['end']: 1684.64
guys uh should know I've only been doing ['start']: 1684.64 ['end']: 1686.36
python for about a year ['start']: 1686.36 ['end']: 1688.84
now all right let's give it another try ['start']: 1688.84 ['end']: 1691.48
probably going to have another error ['start']: 1691.48 ['end']: 1692.64
let's find ['start']: 1692.64 ['end']: 1693.96
out okay what is the URL we want to ['start']: 1693.96 ['end']: 1696.24
summarize let's grab it oops let's paste ['start']: 1696.24 ['end']: 1699.76
it in here hit ['start']: 1699.76 ['end']: 1701.64
enter none here is the result none ['start']: 1701.64 ['end']: 1706.44
okay ['start']: 1706.44 ['end']: 1708.72
so no errors but it definitely did not ['start']: 1708.72 ['end']: 1711.48
work here is the result so what are we ['start']: 1711.48 ['end']: 1714.76
doing wrong newsletter crew. run we have ['start']: 1714.76 ['end']: 1720.08
the newsletter crew right here ['start']: 1720.08 ['end']: 1723.159
run then we have the agents that get ['start']: 1723.159 ['end']: 1727.039
defined the tasks the new oh we don't ['start']: 1727.039 ['end']: 1730.24
actually kick it off here that's the ['start']: 1730.24 ['end']: 1732.519
problem ['start']: 1732.519 ['end']: 1734.72
okay so let's copy that and we want to ['start']: 1734.72 ['end']: 1737.519
do. kickoff I think maybe this will work ['start']: 1737.519 ['end']: 1741.6
let's see hit ['start']: 1741.6 ['end']: 1743.519
play we're going to need that article ['start']: 1743.519 ['end']: 1745.919
again switch back URL you want to ['start']: 1745.919 ['end']: 1748.399
summarize hit play all right I think ['start']: 1748.399 ['end']: 1751.84
that ['start']: 1751.84 ['end']: 1753.159
worked except is it actually ['start']: 1753.159 ['end']: 1760.2
inserting I I am unable to surf the ['start']: 1760.2 ['end']: 1763.919
Internet or access URLs directly however ['start']: 1763.919 ['end']: 1766.12
the tools I'm provided with do not allow ['start']: 1766.12 ['end']: 1768.64
me to directly scrape data from ['start']: 1768.64 ['end']: 1771.279
websites well that's not ['start']: 1771.279 ['end']: 1774.32
helpful okay yeah it's telling me it ['start']: 1774.32 ['end']: 1777.32
can't access the website but that is not ['start']: 1777.32 ['end']: 1782.399
true here is the result none so why is ['start']: 1782.399 ['end']: 1785.36
it telling me ['start']: 1785.36 ['end']: 1786.6
that so all the code looks to be correct ['start']: 1786.6 ['end']: 1789.36
right now but I think what we're going ['start']: 1789.36 ['end']: 1790.519
to have to do is give it a little ['start']: 1790.519 ['end']: 1793.36
nudge to actually be able to go in and ['start']: 1793.36 ['end']: 1797.44
scrape the website and gp4 thinks it ['start']: 1797.44 ['end']: 1799.96
can't but you need to use the tool I ['start']: 1799.96 ['end']: 1802.08
gave ['start']: 1802.08 ['end']: 1804.36
you so here's the website Search tool ['start']: 1804.36 ['end']: 1807.519
which might not actually be what we ['start']: 1807.519 ['end']: 1809.24
think it is but let's find ['start']: 1809.24 ['end']: 1812.399
out and so rather than saying then go to ['start']: 1812.399 ['end']: 1815.36
each given website what we're going to ['start']: 1815.36 ['end']: 1816.919
say is then use the ['start']: 1816.919 ['end']: 1820.72
website Search tool ['start']: 1820.72 ['end']: 1825.799
to then ['start']: 1825.799 ['end']: 1827.799
scrape the content let's see if that ['start']: 1827.799 ['end']: 1831.24
helps ['start']: 1831.24 ['end']: 1832.12
us let's hit ['start']: 1832.12 ['end']: 1834.279
play okay I'm sorry for the ['start']: 1834.279 ['end']: 1836.0
misunderstanding I'm sorry for the ['start']: 1836.0 ['end']: 1837.88
confusion but I need the URLs to be able ['start']: 1837.88 ['end']: 1840.399
to continue with the task okay so ['start']: 1840.399 ['end']: 1842.039
something I'm doing it is not passing ['start']: 1842.039 ['end']: 1843.679
the URLs in correctly so not everybody ['start']: 1843.679 ['end']: 1847.399
gets to Ping the founder and be like hey ['start']: 1847.399 ['end']: 1849.64
can you help me appreciate you helping ['start']: 1849.64 ['end']: 1851.48
out Joe is the founder of crew AI so ['start']: 1851.48 ['end']: 1854.72
very happy for a little bit of help from ['start']: 1854.72 ['end']: 1856.76
him ['start']: 1856.76 ['end']: 1857.799
I am currently let me actually share my ['start']: 1857.799 ['end']: 1860.32
screen so I'm I'm in the middle of the ['start']: 1860.32 ['end']: 1862.559
video I'm doing a let's build so it's a ['start']: 1862.559 ['end']: 1865.2
very like um kind of slow paced video ['start']: 1865.2 ['end']: 1867.84
going through each step all the errors ['start']: 1867.84 ['end']: 1869.799
are all going to be seen by the ['start']: 1869.799 ['end']: 1871.84
audience I'm using lightning. a as the ['start']: 1871.84 ['end']: 1876.6
uh Cloud ['start']: 1876.6 ['end']: 1877.96
IDE and I set up a crew and what I want ['start']: 1877.96 ['end']: 1882.76
them to do is I want to be able to pass ['start']: 1882.76 ['end']: 1885.12
a set of URLs one of the agents is a ['start']: 1885.12 ['end']: 1888.24
scraper agent that agent is going to go ['start']: 1888.24 ['end']: 1890.919
scrape the websites and bring the ['start']: 1890.919 ['end']: 1892.559
content to the writer agent the writer ['start']: 1892.559 ['end']: 1895.44
agent is then going to write a brief ['start']: 1895.44 ['end']: 1898.36
summary of each of the URLs that I ['start']: 1898.36 ['end']: 1900.6
passed to ['start']: 1900.6 ['end']: 1901.799
it now the first problem is before I had ['start']: 1901.799 ['end']: 1906.279
this used the website Search tool gp4 ['start']: 1906.279 ['end']: 1909.24
says I can't scrape website content and ['start']: 1909.24 ['end']: 1911.72
then I explicitly told it go ahead use ['start']: 1911.72 ['end']: 1914.08
the website Search ['start']: 1914.08 ['end']: 1915.679
tool now it work Works however where I'm ['start']: 1915.679 ['end']: 1918.639
a little bit stuck is I and by the way ['start']: 1918.639 ['end']: 1921.96
I'm using um your web uh stock analysis ['start']: 1921.96 ['end']: 1926.2
tool uh as kind of a reference so I'm ['start']: 1926.2 ['end']: 1929.44
trying to pass in the URLs here but ['start']: 1929.44 ['end']: 1931.44
apparently it is not getting passed in ['start']: 1931.44 ['end']: 1933.6
properly the URLs do get passed in I ['start']: 1933.6 ['end']: 1937.039
believe right here so I have them ['start']: 1937.039 ['end']: 1939.6
available but I'm I you know I'm not ['start']: 1939.6 ['end']: 1942.08
great at Python and I'm probably doing ['start']: 1942.08 ['end']: 1944.36
something wrong but it told me if we ['start']: 1944.36 ['end']: 1946.08
look down here ['start']: 1946.08 ['end']: 1948.919
I'm unable to proceed with the task ['start']: 1948.919 ['end']: 1950.639
without the URLs could you please ['start']: 1950.639 ['end']: 1952.279
provide the URLs so that is the issue ['start']: 1952.279 ['end']: 1955.6
right ['start']: 1955.6 ['end']: 1956.919
here got it got it all right so ['start']: 1956.919 ['end']: 1960.039
basically what is interpolate the URLs ['start']: 1960.039 ['end']: 1962.76
into that task there um where do you ['start']: 1962.76 ['end']: 1966.639
have those Ur where are those URLs ['start']: 1966.639 ['end']: 1968.919
coming from so very similar to how you ['start']: 1968.919 ['end']: 1971.44
did it I'm using Dent to ask a question ['start']: 1971.44 ['end']: 1973.919
immediately what is the URL you want to ['start']: 1973.919 ['end']: 1975.76
summarize so I'm starting with just one ['start']: 1975.76 ['end']: 1978.48
but I'm going to assume I want to kind ['start']: 1978.48 ['end']: 1980.08
of plug in a bunch eventually I just ['start']: 1980.08 ['end']: 1982.48
want to get this to work but they're ['start']: 1982.48 ['end']: 1983.6
coming right ['start']: 1983.6 ['end']: 1984.679
here all right got it and then you ['start']: 1984.679 ['end']: 1986.84
create this newsletter CRS and you P you ['start']: 1986.84 ['end']: 1989.559
pass the URLs for in all right let me ['start']: 1989.559 ['end']: 1992.08
look at the class newsletter crew up ['start']: 1992.08 ['end']: 1996.48
there uh newsletter crew all right it ['start']: 1996.48 ['end']: 1999.12
takes a URL all right so the only thing ['start']: 1999.12 ['end']: 2001.72
that I can see that you're not ['start']: 2001.72 ['end']: 2005.84
referencing is instead of having just ['start']: 2005.84 ['end']: 2008.44
URLs as you have in there and you want ['start']: 2008.44 ['end']: 2011.44
to do self. ['start']: 2011.44 ['end']: 2013.76
URLs uh in the in the ['start']: 2013.76 ['end']: 2019.44
task just like that and then and then ['start']: 2019.44 ['end']: 2022.24
you put an a before the string ['start']: 2022.24 ['end']: 2026.039
starts right after the Des right after ['start']: 2026.039 ['end']: 2028.919
the description ['start']: 2028.919 ['end']: 2032.2
equals ah and that will add ['start']: 2032.2 ['end']: 2034.12
interpolation to it exactly so that'll ['start']: 2034.12 ['end']: 2036.76
allow you toate that string and then you ['start']: 2036.76 ['end']: 2039.32
reference the the instance variable URLs ['start']: 2039.32 ['end']: 2043.0
that you declare upstairs okay very cool ['start']: 2043.0 ['end']: 2045.559
all right let's give this a try I mean I ['start']: 2045.559 ['end']: 2047.48
know this is very basic stuff by the way ['start']: 2047.48 ['end']: 2049.56
um but uh I was excited to show you this ['start']: 2049.56 ['end']: 2052.48
crew and I'm probably going to create a ['start']: 2052.48 ['end']: 2054.679
second crew for a completely different ['start']: 2054.679 ['end']: 2056.359
use case after this but we'll see so ['start']: 2056.359 ['end']: 2059.04
okay I'm going to grab a ['start']: 2059.04 ['end']: 2060.56
URL and by the way I assumed website ['start']: 2060.56 ['end']: 2064.2
Search tool is a website search or a ['start']: 2064.2 ['end']: 2067.56
website scraper is that ['start']: 2067.56 ['end']: 2069.48
correct it's actually a rag searching to ['start']: 2069.48 ['end']: 2072.8
on top of the website so it's going to ['start']: 2072.8 ['end']: 2075.04
actually search for something in that ['start']: 2075.04 ['end']: 2077.879
website and return specific paragraphs ['start']: 2077.879 ['end']: 2080.399
that are kind of like relevant to that ['start']: 2080.399 ['end']: 2082.44
ah so maybe this isn't the best tool to ['start']: 2082.44 ['end']: 2084.56
be using for ['start']: 2084.56 ['end']: 2086.52
scraping yes if you want to do actual ['start']: 2086.52 ['end']: 2089.359
scraping I don't think we have a two for ['start']: 2089.359 ['end']: 2092.56
that yet but uh I can get one up pretty ['start']: 2092.56 ['end']: 2096.2
quickly ['start']: 2096.2 ['end']: 2097.76
do you think or do you know of uh if ['start']: 2097.76 ['end']: 2099.88
Lang chain has any website scraping ['start']: 2099.88 ['end']: 2102.72
tools I'm sure it does otherwise I'll ['start']: 2102.72 ['end']: 2105.88
just have to write it myself which is ['start']: 2105.88 ['end']: 2108.359
fine yeah I'm not sure if it does I can ['start']: 2108.359 ['end']: 2113.92
look it up in the past what I have done ['start']: 2113.92 ['end']: 2117.079
is I basically did my own using uh ['start']: 2117.079 ['end']: 2120.2
unstructured like this library from U ['start']: 2120.2 ['end']: 2123.4
this library that basically cleans up ['start']: 2123.4 ['end']: 2125.04
HTML so that's what I have done in the ['start']: 2125.04 ['end']: 2127.119
past and I probably have it like in some ['start']: 2127.119 ['end']: 2129.079
example somewhere I can I can grab and ['start']: 2129.079 ['end']: 2131.28
send it over to you sure I mean that'd ['start']: 2131.28 ['end']: 2133.0
be helpful I'll I'll try to use chat GPT ['start']: 2133.0 ['end']: 2135.32
to help me write a a scraping tool and ['start']: 2135.32 ['end']: 2137.599
um we we'll see if it works but I um ['start']: 2137.599 ['end']: 2140.32
yeah I think that would be a good time ['start']: 2140.32 ['end']: 2142.28
to just create a tool for like a custom ['start']: 2142.28 ['end']: 2145.32
tool for this agent team to use all ['start']: 2145.32 ['end']: 2148.52
right well thank you I appreciate the ['start']: 2148.52 ['end']: 2150.44
help uh I am going to get back to ['start']: 2150.44 ['end']: 2152.359
building this crew and hopefully I can ['start']: 2152.359 ['end']: 2154.52
make it work by the end of this video ['start']: 2154.52 ['end']: 2156.44
have a good bye okay so I just got off a ['start']: 2156.44 ['end']: 2159.68
call with the founder of crew aai and he ['start']: 2159.68 ['end']: 2162.2
explained a few things I was doing wrong ['start']: 2162.2 ['end']: 2164.24
so first right here we actually have to ['start']: 2164.24 ['end']: 2167.079
reference self. URLs to interpolate ['start']: 2167.079 ['end']: 2169.96
properly and we have to add the F at the ['start']: 2169.96 ['end']: 2172.16
beginning of the string so that it knows ['start']: 2172.16 ['end']: 2174.2
we are trying to ['start']: 2174.2 ['end']: 2175.52
interpolate now back at the top one ['start']: 2175.52 ['end']: 2178.92
thing he mentioned is this website ['start']: 2178.92 ['end']: 2180.8
Search tool is not actually what I ['start']: 2180.8 ['end']: 2182.64
thought it was so what this does is it ['start']: 2182.64 ['end']: 2185.4
will uh use rag it will grab all the ['start']: 2185.4 ['end']: 2188.44
content from a website and then you can ['start']: 2188.44 ['end']: 2189.96
actually search through the content of ['start']: 2189.96 ['end']: 2191.68
that website using rag so really cool ['start']: 2191.68 ['end']: 2193.839
tool but not what we need what we need ['start']: 2193.839 ['end']: 2196.56
to do is have a website scraper so we're ['start']: 2196.56 ['end']: 2200.28
going to have to create a custom tool ['start']: 2200.28 ['end']: 2202.28
just for that let's do that ['start']: 2202.28 ['end']: 2205.2
now so we're going to go ahead might as ['start']: 2205.2 ['end']: 2207.64
well just delete ['start']: 2207.64 ['end']: 2209.119
this I am going to remove all of these ['start']: 2209.119 ['end']: 2212.16
tools commented out for ['start']: 2212.16 ['end']: 2214.599
now CU we're not going to need them ['start']: 2214.599 ['end']: 2217.64
and let's go see how to create a custom ['start']: 2217.64 ['end']: 2224.359
tool so in his stock analysis example we ['start']: 2224.359 ['end']: 2228.76
have this tools folder and if we open it ['start']: 2228.76 ['end']: 2231.44
up we have calculator tools browser ['start']: 2231.44 ['end']: 2234.319
tools so I think we're going to have to ['start']: 2234.319 ['end']: 2235.76
do something like ['start']: 2235.76 ['end']: 2239.76
this so I'm going to copy this it's not ['start']: 2239.76 ['end']: 2242.44
going to be a lang chain tool so we're ['start']: 2242.44 ['end']: 2245.56
going to have to create it from scratch ['start']: 2245.56 ['end']: 2247.0
but let's do ['start']: 2247.0 ['end']: 2250.119
that let's switch back I am going to ['start']: 2250.119 ['end']: 2254.24
create a new folder called ['start']: 2254.24 ['end']: 2258.52
tools then I'm going to create a new ['start']: 2258.52 ['end']: 2260.64
file within that folder called scraper ['start']: 2260.64 ['end']: 2264.68
dopy and I'm going to paste that code in ['start']: 2264.68 ['end']: 2267.4
and let's just call this scraper ['start']: 2267.4 ['end']: 2271.68
tools let me just make sure it all yep ['start']: 2271.68 ['end']: 2274.48
so that's how he did it so scraper ['start']: 2274.48 ['end']: 2277.76
actually if we go back it's actually ['start']: 2277.76 ['end']: 2280.16
called calculator tools right so let's ['start']: 2280.16 ['end']: 2282.56
make it match the class ['start']: 2282.56 ['end']: 2284.92
name so rename scraper uncore ['start']: 2284.92 ['end']: 2289.359
tools okay so at ['start']: 2289.359 ['end']: 2293.48
tool scrape website ['start']: 2293.48 ['end']: 2297.88
content text ['start']: 2297.88 ['end']: 2300.8
only okay and then we'll put a nice ['start']: 2300.8 ['end']: 2304.68
little comment at the top useful to to ['start']: 2304.68 ['end']: 2307.52
scrape content of a ['start']: 2307.52 ['end']: 2312.319
website and we probably don't need the ['start']: 2312.319 ['end']: 2314.68
triple quotes but we'll leave them there ['start']: 2314.68 ['end']: 2316.119
anyways and then return eval operation ['start']: 2316.119 ['end']: 2318.92
that is not what we need to do so what ['start']: 2318.92 ['end']: 2320.52
we need to do we'll say return ['start']: 2320.52 ['end']: 2324.2
text ['start']: 2324.2 ['end']: 2325.76
and rather than calculate let's call it ['start']: 2325.76 ['end']: 2330.16
def scrape and this will be ['start']: 2330.16 ['end']: 2334.319
URL okay so now I'm going to switch over ['start']: 2334.319 ['end']: 2336.52
over to chat ['start']: 2336.52 ['end']: 2337.72
GPT and I'm going to ask it to help me ['start']: 2337.72 ['end']: 2339.96
create a scraping ['start']: 2339.96 ['end']: 2342.48
tool so wrer website scraping tool using ['start']: 2342.48 ['end']: 2345.92
python so it looks like it's going to be ['start']: 2345.92 ['end']: 2347.88
using requests and beautiful ['start']: 2347.88 ['end']: 2350.839
soup so I'm going to have to install ['start']: 2350.839 ['end']: 2353.92
that so let's do that first so down here ['start']: 2353.92 ['end']: 2357.319
let's close this thread then I'm going ['start']: 2357.319 ['end']: 2359.92
to say pip install request and beautiful ['start']: 2359.92 ['end']: 2361.56
soup ['start']: 2361.56 ['end']: 2363.0
4 and already satisfied so that's good ['start']: 2363.0 ['end']: 2366.0
it's already there then we're going to ['start']: 2366.0 ['end']: 2369.28
copy this code switch back to our tool ['start']: 2369.28 ['end']: 2373.48
let paste it right here and what we're ['start']: 2373.48 ['end']: 2375.88
going to have to do is at the ['start']: 2375.88 ['end']: 2378.28
top We'll add our Imports the URL we ['start']: 2378.28 ['end']: 2382.96
should actually get ['start']: 2382.96 ['end']: 2386.2
from the URL so we're going to ['start']: 2386.2 ['end']: 2388.8
instantiate it with a URL I think that's ['start']: 2388.8 ['end']: 2391.96
the best way to do ['start']: 2391.96 ['end']: 2394.079
it it says scrape title but that's not ['start']: 2394.079 ['end']: 2397.48
what we need right we don't want it to ['start']: 2397.48 ['end']: 2400.119
scrape the titles so let's actually ask ['start']: 2400.119 ['end']: 2402.319
it for a slightly different code please ['start']: 2402.319 ['end']: 2405.24
make the code scrape all ['start']: 2405.24 ['end']: 2410.2
text content from the ['start']: 2410.2 ['end']: 2416.599
website o it's bugging out a little ['start']: 2416.599 ['end']: 2420.64
bit wow it is wacky right ['start']: 2420.64 ['end']: 2425.2
now okay this is barely working it seems ['start']: 2425.2 ['end']: 2429.16
to be outputting but for some reason the ['start']: 2429.16 ['end']: 2431.16
scroll bar is jumping ['start']: 2431.16 ['end']: 2435.4
around okay so it looks like it fixed ['start']: 2435.4 ['end']: 2438.52
itself so now here scrape all text ['start']: 2438.52 ['end']: 2441.72
getting the ['start']: 2441.72 ['end']: 2442.72
URL parsing removing the ['start']: 2442.72 ['end']: 2448.04
elements okay so I'm going to copy this ['start']: 2448.04 ['end']: 2450.56
code let's go back to ['start']: 2450.56 ['end']: 2452.52
lightning and I'm going to replace all ['start']: 2452.52 ['end']: 2454.8
that okay so we don't need to import ['start']: 2454.8 ['end']: 2457.2
these again okay so I'm going to ['start']: 2457.2 ['end']: 2460.68
take all of ['start']: 2460.68 ['end']: 2465.4
that right there all of the main ['start']: 2465.4 ['end']: 2468.44
code and let's put it into ['start']: 2468.44 ['end']: 2473.16
here we'll delete this at the end and ['start']: 2473.16 ['end']: 2476.319
we're going to return text which seems ['start']: 2476.319 ['end']: 2479.599
correct but it is not so instead of ['start']: 2479.599 ['end']: 2483.16
printing right there we're going to just ['start']: 2483.16 ['end']: 2485.96
return ['start']: 2485.96 ['end']: 2487.28
combined text now we may have an issue ['start']: 2487.28 ['end']: 2490.119
that it's including a lot of text that ['start']: 2490.119 ['end']: 2491.56
is not necessarily relevant to ['start']: 2491.56 ['end']: 2493.56
summarizing the article but let's find ['start']: 2493.56 ['end']: 2496.56
out now I'm actually not sure if this is ['start']: 2496.56 ['end']: 2499.599
the proper way to pass in this variable ['start']: 2499.599 ['end']: 2502.76
so I'm going to double check with how ['start']: 2502.76 ['end']: 2505.2
he's doing it so it is not so let's ['start']: 2505.2 ['end']: 2508.079
delete ['start']: 2508.079 ['end']: 2509.119
that I don't think we need ['start']: 2509.119 ['end']: 2513.76
this okay and then ['start']: 2513.76 ['end']: 2518.24
that should be good I think I think that ['start']: 2518.24 ['end']: 2521.0
should ['start']: 2521.0 ['end']: 2522.4
work and so we're going to copy this ['start']: 2522.4 ['end']: 2525.88
switch back to ['start']: 2525.88 ['end']: 2527.56
main.py and let's just see how he ['start']: 2527.56 ['end']: 2529.56
Imports ['start']: 2529.56 ['end']: 2532.8
it so tools dot there we go okay so ['start']: 2532.8 ['end']: 2536.56
that's how he does it so what we're ['start']: 2536.56 ['end']: 2538.0
going to do is from actually we'll put ['start']: 2538.0 ['end']: 2541.119
that at the ['start']: 2541.119 ['end']: 2542.52
top from ['start']: 2542.52 ['end']: 2545.16
tools. scraper ['start']: 2545.16 ['end']: 2547.76
tools then how did he do it ['start']: 2547.76 ['end']: 2552.72
import scraper tools okay hopefully that ['start']: 2552.72 ['end']: 2558.16
works now we need to instantiate scraper ['start']: 2558.16 ['end']: 2562.72
tools scraper ['start']: 2562.72 ['end']: 2565.04
tools ['start']: 2565.04 ['end']: 2567.76
scraper tools is equal to scraper tools ['start']: 2567.76 ['end']: 2571.2
maybe that'll work and then right here ['start']: 2571.2 ['end']: 2573.92
I'm going to input scraper tools so ['start']: 2573.92 ['end']: 2575.599
let's actually capitalize ['start']: 2575.599 ['end']: 2577.8
that like ['start']: 2577.8 ['end']: 2583.119
that ['start']: 2583.119 ['end']: 2584.96
okay maybe this will work let's find out ['start']: 2584.96 ['end']: 2588.04
together so hit ['start']: 2588.04 ['end']: 2590.88
play all right name Tool is not defined ['start']: 2590.88 ['end']: 2594.359
did you mean bu where is ['start']: 2594.359 ['end']: 2597.72
tool at tool scrape website content text ['start']: 2597.72 ['end']: 2601.0
only so there's something wrong ['start']: 2601.0 ['end']: 2604.52
with ah I see so it is the fact that ['start']: 2604.52 ['end']: 2608.599
we're doing this at tool which is not ['start']: 2608.599 ['end']: 2611.4
relevant unless we're using laying chain ['start']: 2611.4 ['end']: 2613.28
so let's go ahead and delete ['start']: 2613.28 ['end']: 2615.72
that because we don't need that and now ['start']: 2615.72 ['end']: 2619.52
that that is fixed let's try it ['start']: 2619.52 ['end']: 2621.44
again okay what is the URL of the ['start']: 2621.44 ['end']: 2624.0
website you want to summarize let's grab ['start']: 2624.0 ['end']: 2625.64
that URL paste it in hit enter all right ['start']: 2625.64 ['end']: 2629.599
key error tools so we still have an ['start']: 2629.599 ['end']: 2632.76
issue so this is on AG agent. ['start']: 2632.76 ['end']: 2637.76
Pi nope not ['start']: 2637.76 ['end']: 2641.44
there main. Pi line ['start']: 2641.44 ['end']: 2645.079
16 ['start']: 2645.079 ['end']: 2646.92
scraper main. Pi line ['start']: 2646.92 ['end']: 2650.839
66 okay no so it's keyword key error ['start']: 2650.839 ['end']: 2654.8
tools so I think it's ['start']: 2654.8 ['end']: 2657.76
this that's causing the ['start']: 2657.76 ['end']: 2665.0
error ['start']: 2665.0 ['end']: 2667.599
so one really cool thing is I just put ['start']: 2667.599 ['end']: 2670.72
this session live and I'm giving it to ['start']: 2670.72 ['end']: 2673.359
somebody to help me out uh that is a ['start']: 2673.359 ['end']: 2675.8
really awesome feature of lightning and ['start']: 2675.8 ['end']: 2678.119
look at that now he's in here taking a ['start']: 2678.119 ['end']: 2681.72
look at the code in real time this is ['start']: 2681.72 ['end']: 2684.52
cool uh I think I like Cloud editing ['start']: 2684.52 ['end']: 2688.28
much more than local editing now so ['start']: 2688.28 ['end']: 2690.44
maybe I should think about doing live ['start']: 2690.44 ['end']: 2692.0
coding sessions going forward maybe I'll ['start']: 2692.0 ['end']: 2694.4
put it live on YouTube and actually do ['start']: 2694.4 ['end']: 2696.48
it live through lightning. if you want ['start']: 2696.48 ['end']: 2699.0
to see that let me know in the comments ['start']: 2699.0 ['end']: 2700.839
below okay so we can see the changes ['start']: 2700.839 ['end']: 2703.24
he's making in real time okay so I ['start']: 2703.24 ['end']: 2706.24
changed a few things so we are going to ['start']: 2706.24 ['end']: 2709.4
use Lang chain tools import tool as the ['start']: 2709.4 ['end']: 2712.44
way to actually Define the tool then we ['start']: 2712.44 ['end']: 2715.559
can use at tool right ['start']: 2715.559 ['end']: 2718.44
there and everything else is pretty much ['start']: 2718.44 ['end']: 2721.16
the same now one problem I'm running ['start']: 2721.16 ['end']: 2723.4
into is that the website I want to ['start']: 2723.4 ['end']: 2725.96
scrape is actually just blocking the ['start']: 2725.96 ['end']: 2727.599
request so I'm going to tell chat GPT ['start']: 2727.599 ['end']: 2729.68
this and let's see if it can give me ['start']: 2729.68 ['end']: 2731.2
another method to scrape the ['start']: 2731.2 ['end']: 2733.96
website okay so everything works and ['start']: 2733.96 ['end']: 2736.079
then it says failed to retrieve the web ['start']: 2736.079 ['end']: 2738.64
page so I'm going to copy that put it in ['start']: 2738.64 ['end']: 2741.76
here and I'm going to say is there a ['start']: 2741.76 ['end']: 2744.52
better way ['start']: 2744.52 ['end']: 2746.0
to retrieve the website ['start']: 2746.0 ['end']: 2750.52
content use headers to mimic a browser ['start']: 2750.52 ['end']: 2753.559
that's what we need to do ['start']: 2753.559 ['end']: 2756.48
okay so let's copy that code so let's ['start']: 2756.48 ['end']: 2758.52
make it look like we are an actual ['start']: 2758.52 ['end']: 2760.28
browser that's the ['start']: 2760.28 ['end']: 2762.0
problem so right before this we're going ['start']: 2762.0 ['end']: 2764.68
to enter the code we just got now we ['start']: 2764.68 ['end']: 2766.839
already have this stuff so let's get rid ['start']: 2766.839 ['end']: 2768.72
of that we don't need the URL cuz we're ['start']: 2768.72 ['end']: 2771.72
going to be passing that ['start']: 2771.72 ['end']: 2773.2
in and we will need the headers so let's ['start']: 2773.2 ['end']: 2777.88
put that ['start']: 2777.88 ['end']: 2781.04
there okay and scrape all text so we ['start']: 2781.04 ['end']: 2785.28
don't need to find it ['start']: 2785.28 ['end']: 2789.599
again response equals so we're going to ['start']: 2789.599 ['end']: 2792.0
be passing in the headers this time and ['start']: 2792.0 ['end']: 2794.76
then everything else should be the same ['start']: 2794.76 ['end']: 2798.4
as we have it ['start']: 2798.4 ['end']: 2803.079
before okay I think this may work now ['start']: 2803.079 ['end']: 2808.28
let's give it a try so I'm going to ['start']: 2808.28 ['end']: 2810.28
clear all the output in the terminal ['start']: 2810.28 ['end']: 2812.319
let's play ['start']: 2812.319 ['end']: 2814.8
it ['start']: 2814.8 ['end']: 2817.88
what is the URL you want to ['start']: 2817.88 ['end']: 2822.359
summarize ['start']: 2822.359 ['end']: 2826.2
okay failed to retrieve the web page ['start']: 2826.2 ['end']: 2828.839
again darn ['start']: 2828.839 ['end']: 2835.76
it okay let's ['start']: 2835.76 ['end']: 2838.599
see if it'll work on the crew aai ['start']: 2838.599 ['end']: 2841.76
website maybe it is that ['start']: 2841.76 ['end']: 2844.72
simple ['start']: 2844.72 ['end']: 2847.319
maybe it's just continuing to block my ['start']: 2847.319 ['end']: 2849.64
request because it thinks I'm a scraper ['start']: 2849.64 ['end']: 2851.28
which I am but that is besides the point ['start']: 2851.28 ['end']: 2853.839
what is the URL you want to summarize ['start']: 2853.839 ['end']: 2855.559
crew ai.com ['start']: 2855.559 ['end']: 2858.72
okay invalid URL crew ai.com crew ai.com ['start']: 2858.72 ['end']: 2863.8
perhaps you meant okay so we should ['start']: 2863.8 ['end']: 2866.2
definitely fix that but that's okay ['start']: 2866.2 ['end']: 2869.119
let's give ['start']: 2869.119 ['end']: 2870.96
it the full URL ['start']: 2870.96 ['end']: 2874.04
now okay so it should be be out scraping ['start']: 2874.04 ['end']: 2876.64
there we go perfect so it is working ['start']: 2876.64 ['end']: 2878.599
properly I'm going to go ahead and stop ['start']: 2878.599 ['end']: 2880.92
that so now we know it's working ['start']: 2880.92 ['end']: 2882.44
properly so the problem is this website ['start']: 2882.44 ['end']: 2884.72
is still blocking our attempt to scrape ['start']: 2884.72 ['end']: 2888.24
it so back to uh back to chat gbt still ['start']: 2888.24 ['end']: 2891.839
getting failed to retrieve website is ['start']: 2891.839 ['end']: 2893.119
there another way to scrape the ['start']: 2893.119 ['end']: 2894.96
website libraries like fake user agent ['start']: 2894.96 ['end']: 2897.68
can help Generate random realistic user ['start']: 2897.68 ['end']: 2899.68
agent strings for each request all right ['start']: 2899.68 ['end']: 2902.599
let's see if that ['start']: 2902.599 ['end']: 2904.079
works third party tools and services ['start']: 2904.079 ['end']: 2907.559
using API end points instead of ['start']: 2907.559 ['end']: 2912.52
scraping okay sample scrapey with Splash ['start']: 2912.52 ['end']: 2916.16
code ['start']: 2916.16 ['end']: 2917.8
snippet this is getting complex more ['start']: 2917.8 ['end']: 2920.44
complex than I was ['start']: 2920.44 ['end']: 2921.92
hoping let me try actually a different ['start']: 2921.92 ['end']: 2924.2
URL I just want to get this to work at ['start']: 2924.2 ['end']: 2926.2
this ['start']: 2926.2 ['end']: 2927.359
point all right here's another article ['start']: 2927.359 ['end']: 2929.92
by a website payments.com report open AI ['start']: 2929.92 ['end']: 2932.96
surpasses 2 billion and annualize ['start']: 2932.96 ['end']: 2934.72
revenue back to to lightning AI let's ['start']: 2934.72 ['end']: 2937.44
try it again but this time we're going ['start']: 2937.44 ['end']: 2940.48
to use that website and hopefully they ['start']: 2940.48 ['end']: 2942.119
don't have as sophisticated of scraping ['start']: 2942.119 ['end']: 2947.0
blockers boom let's ['start']: 2947.0 ['end']: 2951.92
see I think it's ['start']: 2951.92 ['end']: 2954.16
working yep oh it worked but then we ['start']: 2954.16 ['end']: 2957.599
have an error let's see what it is ['start']: 2957.599 ['end']: 2960.0
please reduce the length of messages ah ['start']: 2960.0 ['end']: 2963.079
so now we're getting an open AI issue ['start']: 2963.079 ['end']: 2965.799
this model this model's maximum context ['start']: 2965.799 ['end']: 2968.359
length is 8,000 ['start']: 2968.359 ['end']: 2971.359
tokens okay yeah we're passing a lot in ['start']: 2971.359 ['end']: 2975.92
there a ton ['start']: 2975.92 ['end']: 2978.839
actually okay ['start']: 2978.839 ['end']: 2981.64
so let me see maybe there's a way to ['start']: 2981.64 ['end']: 2985.68
identify the actual content of the ['start']: 2985.68 ['end']: 2991.4
article ah yes because this is the ['start']: 2991.4 ['end']: 2994.52
homepage okay so it's just a scrolling ['start']: 2994.52 ['end']: 3000.4
list so maybe there's a way to get the ['start']: 3000.4 ['end']: 3004.839
direct ['start']: 3004.839 ['end']: 3006.48
text okay I'm going to ask chat ['start']: 3006.48 ['end']: 3009.28
GPT so ['start']: 3009.28 ['end']: 3011.68
I've gone back to the previous scraping ['start']: 3011.68 ['end']: 3015.24
method on ['start']: 3015.24 ['end']: 3017.2
another website which ['start']: 3017.2 ['end']: 3019.92
works how do I make sure to only grab ['start']: 3019.92 ['end']: 3025.119
the ['start']: 3025.119 ['end']: 3026.16
topmost ['start']: 3026.16 ['end']: 3028.2
article text and nothing ['start']: 3028.2 ['end']: 3032.359
else okay so you need to First identify ['start']: 3032.359 ['end']: 3034.88
how the website's HTML structure ['start']: 3034.88 ['end']: 3036.92
distinguishes the top article from the ['start']: 3036.92 ['end']: 3038.559
others using specific tags so here's an ['start']: 3038.559 ['end']: 3042.599
example right clicking and hit inspect ['start']: 3042.599 ['end']: 3045.799
yeah that sounds good let's try ['start']: 3045.799 ['end']: 3050.72
that so we'll look for this right here ['start']: 3050.72 ['end']: 3054.4
we're going to right click we're we're ['start']: 3054.4 ['end']: 3055.48
going to hit inspect and we're going to ['start']: 3055.48 ['end']: 3056.559
look for some kind of ['start']: 3056.559 ['end']: 3060.079
tag that it might be let's ['start']: 3060.079 ['end']: 3063.48
see Post Feed ['start']: 3063.48 ['end']: 3066.76
text all right insert article that'll ['start']: 3066.76 ['end']: 3070.119
get rid of some ['start']: 3070.119 ['end']: 3082.68
stuff okay so it looks like it uses ID ['start']: 3082.68 ['end']: 3085.44
equals insert article let's only target ['start']: 3085.44 ['end']: 3086.96
text within ['start']: 3086.96 ['end']: 3089.48
that ah and I actually typed it wrong ['start']: 3089.48 ['end']: 3092.04
it's insert uppercase ['start']: 3092.04 ['end']: 3095.24
article I really wish I had a bigger ['start']: 3095.24 ['end']: 3097.4
context window right about ['start']: 3097.4 ['end']: 3101.839
now okay so I'm going to ['start']: 3101.839 ['end']: 3105.799
copy go back to the ['start']: 3105.799 ['end']: 3108.64
code scraper tools and let's see what ['start']: 3108.64 ['end']: 3111.64
the difference ['start']: 3111.64 ['end']: 3114.359
is so here we go article this is going ['start']: 3114.359 ['end']: 3117.839
to be the difference right there and I'm ['start']: 3117.839 ['end']: 3121.079
going to just grab this whole amount of ['start']: 3121.079 ['end']: 3122.76
code right there switch ['start']: 3122.76 ['end']: 3129.44
back okay so text element is find ['start']: 3129.44 ['end']: 3133.28
all article equals soup. find so I'm ['start']: 3133.28 ['end']: 3136.88
going to delete this we're not going to ['start']: 3136.88 ['end']: 3138.72
find all ['start']: 3138.72 ['end']: 3140.359
anymore and we're going to say ['start']: 3140.359 ['end']: 3142.799
insert article now this is just going to ['start']: 3142.799 ['end']: 3145.119
work for this website obviously so I'm ['start']: 3145.119 ['end']: 3147.04
going to need to mess around with the ['start']: 3147.04 ['end']: 3148.96
scraper tool to make it more generally ['start']: 3148.96 ['end']: 3151.119
applicable but for now I just want to ['start']: 3151.119 ['end']: 3152.839
get it to ['start']: 3152.839 ['end']: 3153.96
work so I'm going to say text is equal ['start']: 3153.96 ['end']: 3157.04
to and then it's going to do that then ['start']: 3157.04 ['end']: 3159.76
I'm going to delete this other part ['start']: 3159.76 ['end']: 3161.72
right ['start']: 3161.72 ['end']: 3164.559
here then I'm going to use I'm going to ['start']: 3164.559 ['end']: 3167.76
delete text right ['start']: 3167.76 ['end']: 3170.16
there okay we'll return text and we're ['start']: 3170.16 ['end']: 3172.68
going to ['start']: 3172.68 ['end']: 3174.24
join we don't really need that actually ['start']: 3174.24 ['end']: 3177.48
let's just see what ['start']: 3177.48 ['end']: 3179.24
happens just like that all right let's ['start']: 3179.24 ['end']: 3182.119
play it one more time I'm hoping this ['start']: 3182.119 ['end']: 3188.0
works what is the URL of the article you ['start']: 3188.0 ['end']: 3190.48
want to summarize grab ['start']: 3190.48 ['end']: 3200.88
it okay it should be there we go we got ['start']: 3200.88 ['end']: 3204.16
it ['start']: 3204.16 ['end']: 3206.76
Perfect all right Final Answer perfect ['start']: 3206.76 ['end']: 3209.72
so it grabbed the ['start']: 3209.72 ['end']: 3212.2
text now finish ['start']: 3212.2 ['end']: 3217.76
chain and it gave us a very brief ['start']: 3217.76 ['end']: 3220.48
summary that's good here we go ['start']: 3220.48 ['end']: 3222.16
summarizer of websites entering the crew ['start']: 3222.16 ['end']: 3225.4
delegate work to ['start']: 3225.4 ['end']: 3227.359
coworker now hopefully it's going to ['start']: 3227.359 ['end']: 3230.119
give us a an even briefer summary a re a ['start']: 3230.119 ['end']: 3233.839
rewrite of it ['start']: 3233.839 ['end']: 3237.52
ah failed to retrieve web ['start']: 3237.52 ['end']: 3240.799
page I already Ed a scraper tool with ['start']: 3240.799 ['end']: 3244.2
input blah blah blah so I already know ['start']: 3244.2 ['end']: 3246.119
that and I must stop using it with that ['start']: 3246.119 ['end']: 3248.0
same input Perfect final answer all ['start']: 3248.0 ['end']: 3252.0
right this is exactly what I ['start']: 3252.0 ['end']: 3254.72
needed finished chain hopefully it just ['start']: 3254.72 ['end']: 3258.04
ends ['start']: 3258.04 ['end']: 3259.28
now all right here is the ['start']: 3259.28 ['end']: 3262.04
result and the result is empty but it's ['start']: 3262.04 ['end']: 3264.68
right there ['start']: 3264.68 ['end']: 3267.28
awesome and this is not the text from ['start']: 3267.28 ['end']: 3269.96
the article as far as I know and so ['start']: 3269.96 ['end']: 3272.28
there we go we got a summary of that ['start']: 3272.28 ['end']: 3274.079
article now I'm going to end it here ['start']: 3274.079 ['end']: 3276.2
because this is already a very long ['start']: 3276.2 ['end']: 3277.72
video but in my next video I think I ['start']: 3277.72 ['end']: 3280.44
want to make this much more robust ['start']: 3280.44 ['end']: 3282.76
because I think it has the potential to ['start']: 3282.76 ['end']: 3284.04
be much more robust now this was made ['start']: 3284.04 ['end']: 3287.28
very easy with lightning AI because I ['start']: 3287.28 ['end']: 3289.319
did everything in the cloud I had ['start']: 3289.319 ['end']: 3291.2
someone help me live right in front of ['start']: 3291.2 ['end']: 3293.319
my eyes in the cloud which was super ['start']: 3293.319 ['end']: 3295.04
super awesome and not only that I've ['start']: 3295.04 ['end']: 3297.64
only scratched the surface of what's ['start']: 3297.64 ['end']: 3299.4
possible with lightning AI because you ['start']: 3299.4 ['end']: 3301.4
can load models you can fine tune models ['start']: 3301.4 ['end']: 3303.64
you can actually run models in the cloud ['start']: 3303.64 ['end']: 3307.76
powering your agents and all of this is ['start']: 3307.76 ['end']: 3311.04
done through lightning AI so thank you ['start']: 3311.04 ['end']: 3313.359
so much to the sponsor of this video ['start']: 3313.359 ['end']: 3314.92
lightning AI check them out I'll drop a ['start']: 3314.92 ['end']: 3317.0
link in the description below where you ['start']: 3317.0 ['end']: 3318.48
can find out more and get set up with ['start']: 3318.48 ['end']: 3320.72
them I highly recommend it you saw it in ['start']: 3320.72 ['end']: 3323.2
action it's awesome if you like this ['start']: 3323.2 ['end']: 3325.319
video please consider giving a like And ['start']: 3325.319 ['end']: 3327.039
subscribe and I'll see you in the next ['start']: 3327.039 ['end']: 3328.76
